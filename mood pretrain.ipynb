{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data\n",
    "data = pd.read_csv(\"data_moods.csv\")\n",
    "truck_data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "numeric_cols = ['danceability', 'acousticness', 'energy', 'instrumentalness', 'liveness', 'valence',  'speechiness']\n",
    "\n",
    "# Round to two decimal places and multiply by 100\n",
    "for col in numeric_cols:\n",
    "    data[col] = (data[col] * 100).round(0)\n",
    "    truck_data[col] = (truck_data[col] * 100).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>length</th>\n",
       "      <th>danceability</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>Prince</td>\n",
       "      <td>2H7PHVdQ3mXqEHXcvclTB0</td>\n",
       "      <td>1982-10-27</td>\n",
       "      <td>68</td>\n",
       "      <td>379266</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-8.20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>118.52</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>Blonde Redhead</td>\n",
       "      <td>4HIwL9ii9CcXpTOTzMq0MP</td>\n",
       "      <td>2007-04-16</td>\n",
       "      <td>43</td>\n",
       "      <td>318800</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 Crimes</td>\n",
       "      <td>9</td>\n",
       "      <td>Damien Rice</td>\n",
       "      <td>5GZEeowhvSieFDiR8fQ2im</td>\n",
       "      <td>2006-11-06</td>\n",
       "      <td>60</td>\n",
       "      <td>217946</td>\n",
       "      <td>35.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-15.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136.17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99 Luftballons</td>\n",
       "      <td>99 Luftballons</td>\n",
       "      <td>Nena</td>\n",
       "      <td>6HA97v4wEGQ5TUClRM0XLc</td>\n",
       "      <td>1984-08-21</td>\n",
       "      <td>2</td>\n",
       "      <td>233000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-12.86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>193.10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Boy Brushed Red Living In Black And White</td>\n",
       "      <td>They're Only Chasing Safety</td>\n",
       "      <td>Underoath</td>\n",
       "      <td>47IWLfIKOKhFnz1FUEUIkE</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>268000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>169.88</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name                        album  \\\n",
       "0                                         1999                         1999   \n",
       "1                                           23                           23   \n",
       "2                                     9 Crimes                            9   \n",
       "3                               99 Luftballons               99 Luftballons   \n",
       "4  A Boy Brushed Red Living In Black And White  They're Only Chasing Safety   \n",
       "\n",
       "           artist                      id release_date  popularity  length  \\\n",
       "0          Prince  2H7PHVdQ3mXqEHXcvclTB0   1982-10-27          68  379266   \n",
       "1  Blonde Redhead  4HIwL9ii9CcXpTOTzMq0MP   2007-04-16          43  318800   \n",
       "2     Damien Rice  5GZEeowhvSieFDiR8fQ2im   2006-11-06          60  217946   \n",
       "3            Nena  6HA97v4wEGQ5TUClRM0XLc   1984-08-21           2  233000   \n",
       "4       Underoath  47IWLfIKOKhFnz1FUEUIkE   2004-01-01          60  268000   \n",
       "\n",
       "   danceability  acousticness  energy  instrumentalness  liveness  valence  \\\n",
       "0          87.0          14.0    73.0               0.0       8.0     62.0   \n",
       "1          38.0           2.0    83.0              20.0      15.0     17.0   \n",
       "2          35.0          91.0    14.0               0.0       9.0     12.0   \n",
       "3          47.0           9.0    44.0               0.0      11.0     59.0   \n",
       "4          42.0           0.0    93.0               0.0      14.0     44.0   \n",
       "\n",
       "   loudness  speechiness   tempo  key  time_signature       mood  \n",
       "0     -8.20          8.0  118.52    5               4      Happy  \n",
       "1     -5.07          5.0  120.26    8               4        Sad  \n",
       "2    -15.33          3.0  136.17    0               4        Sad  \n",
       "3    -12.86          6.0  193.10    4               4      Happy  \n",
       "4     -3.60         11.0  169.88    1               4  Energetic  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['danceability', 'acousticness', 'energy', 'instrumentalness', 'liveness', 'valence', 'loudness', 'speechiness', 'tempo', 'key']\n",
    "X = data[features]\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['mood'])\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "X_pre= truck_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>46.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-14.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>69.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-3.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>123.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>57.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-14.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.92</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>28.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98.66</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-5.98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>127.97</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-4.18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150.12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>27.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-33.73</td>\n",
       "      <td>5.0</td>\n",
       "      <td>132.58</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-10.64</td>\n",
       "      <td>5.0</td>\n",
       "      <td>142.72</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>30.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-18.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>121.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  acousticness  energy  instrumentalness  liveness  valence  \\\n",
       "278          46.0          92.0    18.0               0.0      12.0     18.0   \n",
       "110          69.0          10.0    96.0               1.0       8.0     45.0   \n",
       "82           74.0          95.0    31.0               0.0      19.0     36.0   \n",
       "51           57.0          84.0    16.0               0.0       9.0      9.0   \n",
       "218          28.0          85.0    26.0               0.0      10.0     11.0   \n",
       "..            ...           ...     ...               ...       ...      ...   \n",
       "71           60.0           2.0    90.0              68.0      10.0     14.0   \n",
       "106          70.0           0.0    68.0               0.0       6.0     55.0   \n",
       "270          27.0          99.0     0.0              89.0       9.0     15.0   \n",
       "435          30.0          17.0    54.0              80.0      13.0     19.0   \n",
       "102          30.0          93.0    23.0              90.0      10.0      6.0   \n",
       "\n",
       "     loudness  speechiness   tempo  key  \n",
       "278    -14.85          4.0   80.75    0  \n",
       "110     -3.66         11.0  123.98    1  \n",
       "82      -7.83          7.0  111.20    4  \n",
       "51     -14.40          3.0  109.92    6  \n",
       "218     -9.87          3.0   98.66   11  \n",
       "..        ...          ...     ...  ...  \n",
       "71      -5.98          5.0  127.97    5  \n",
       "106     -4.18          6.0  150.12    2  \n",
       "270    -33.73          5.0  132.58    7  \n",
       "435    -10.64          5.0  142.72    7  \n",
       "102    -18.33          3.0  121.60    1  \n",
       "\n",
       "[548 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to a textual format\n",
    "text_data_train = X_train.apply(lambda x: ', '.join(f\"{feature}: {x[feature]}\" for feature in features), axis=1).tolist()\n",
    "text_data_val = X_val.apply(lambda x: ', '.join(f\"{feature}: {x[feature]}\" for feature in features), axis=1).tolist()\n",
    "text_data_pre=X_pre.apply(lambda x: ', '.join(f\"{feature}: {x[feature]}\" for feature in features), axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Now, you can tokenize your data\n",
    "train_encodings = tokenizer(text_data_train, truncation=True, padding=True, return_tensors=\"pt\", max_length=128)\n",
    "val_encodings = tokenizer(text_data_val, truncation=True, padding=True, return_tensors=\"pt\", max_length=128)\n",
    "pred_encoding=tokenizer(text_data_pre, truncation=True, padding=True, return_tensors=\"pt\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "#model = GPT2ForSequenceClassification.from_pretrained(\"distilgpt2\", num_labels=4)\n",
    "#model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=4)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2-large\", num_labels=4)\n",
    "#model = GPT2ForSequenceClassification.from_pretrained(\"gpt2-xl\", num_labels=4)\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class MoodDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure labels are of type torch.long\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MoodDataset(train_encodings, y_train)\n",
    "val_dataset = MoodDataset(val_encodings, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',   # Add this line to specify the output directory\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/690 [00:00<?, ?it/s]C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  0%|          | 1/690 [00:01<13:03,  1.14s/it]C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  2%|▏         | 11/690 [00:03<02:39,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8957, 'learning_rate': 4.9275362318840584e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 21/690 [00:05<02:38,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3993, 'learning_rate': 4.855072463768116e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 31/690 [00:08<02:38,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3368, 'learning_rate': 4.782608695652174e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 41/690 [00:10<02:25,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1913, 'learning_rate': 4.710144927536232e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 51/690 [00:12<02:23,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8772, 'learning_rate': 4.63768115942029e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 61/690 [00:14<02:11,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9334, 'learning_rate': 4.565217391304348e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 10%|█         | 69/690 [00:17<02:03,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7001689672470093, 'eval_accuracy': 0.7246376811594203, 'eval_runtime': 0.7592, 'eval_samples_per_second': 181.773, 'eval_steps_per_second': 23.71, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 10%|█         | 71/690 [00:26<23:41,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8297, 'learning_rate': 4.492753623188406e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 81/690 [00:28<02:42,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7305, 'learning_rate': 4.4202898550724645e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 91/690 [00:30<02:04,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7583, 'learning_rate': 4.347826086956522e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 101/690 [00:32<02:01,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8702, 'learning_rate': 4.27536231884058e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 111/690 [00:35<02:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8109, 'learning_rate': 4.202898550724638e-05, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 121/690 [00:37<01:57,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7228, 'learning_rate': 4.130434782608696e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 131/690 [00:39<01:54,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.739, 'learning_rate': 4.057971014492754e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 20%|██        | 138/690 [00:41<01:47,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6647589802742004, 'eval_accuracy': 0.7318840579710145, 'eval_runtime': 0.7538, 'eval_samples_per_second': 183.068, 'eval_steps_per_second': 23.878, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|██        | 141/690 [00:51<15:19,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5433, 'learning_rate': 3.985507246376812e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 151/690 [00:53<02:12,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6403, 'learning_rate': 3.91304347826087e-05, 'epoch': 2.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 161/690 [00:55<01:49,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1279, 'learning_rate': 3.8405797101449274e-05, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 171/690 [00:57<01:46,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5791, 'learning_rate': 3.7681159420289856e-05, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 181/690 [00:59<01:45,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4933, 'learning_rate': 3.695652173913043e-05, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 191/690 [01:01<01:42,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0612, 'learning_rate': 3.6231884057971014e-05, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 201/690 [01:03<01:39,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5227, 'learning_rate': 3.5507246376811596e-05, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 30%|███       | 207/690 [01:05<01:34,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6571718454360962, 'eval_accuracy': 0.7391304347826086, 'eval_runtime': 0.744, 'eval_samples_per_second': 185.486, 'eval_steps_per_second': 24.194, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 31%|███       | 211/690 [01:15<09:27,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4466, 'learning_rate': 3.478260869565218e-05, 'epoch': 3.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 221/690 [01:17<01:49,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4558, 'learning_rate': 3.405797101449276e-05, 'epoch': 3.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 231/690 [01:19<01:34,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5367, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 241/690 [01:21<01:31,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6143, 'learning_rate': 3.260869565217392e-05, 'epoch': 3.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 251/690 [01:23<01:30,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.494, 'learning_rate': 3.188405797101449e-05, 'epoch': 3.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 261/690 [01:25<01:28,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4046, 'learning_rate': 3.1159420289855074e-05, 'epoch': 3.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 271/690 [01:27<01:26,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3807, 'learning_rate': 3.0434782608695656e-05, 'epoch': 3.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|████      | 276/690 [01:29<01:20,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0575900077819824, 'eval_accuracy': 0.6884057971014492, 'eval_runtime': 0.7421, 'eval_samples_per_second': 185.951, 'eval_steps_per_second': 24.255, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 41%|████      | 281/690 [01:39<06:21,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3811, 'learning_rate': 2.971014492753623e-05, 'epoch': 4.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 291/690 [01:41<01:30,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3569, 'learning_rate': 2.8985507246376814e-05, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 301/690 [01:43<01:20,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4335, 'learning_rate': 2.826086956521739e-05, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 311/690 [01:45<01:17,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2988, 'learning_rate': 2.753623188405797e-05, 'epoch': 4.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 321/690 [01:47<01:15,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3596, 'learning_rate': 2.6811594202898553e-05, 'epoch': 4.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 331/690 [01:49<01:16,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4133, 'learning_rate': 2.608695652173913e-05, 'epoch': 4.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 341/690 [01:51<01:11,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3977, 'learning_rate': 2.5362318840579714e-05, 'epoch': 4.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|█████     | 345/690 [01:53<01:06,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0303715467453003, 'eval_accuracy': 0.7101449275362319, 'eval_runtime': 0.7741, 'eval_samples_per_second': 178.275, 'eval_steps_per_second': 23.253, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 51%|█████     | 351/690 [02:04<04:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4846, 'learning_rate': 2.4637681159420292e-05, 'epoch': 5.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 361/690 [02:06<01:18,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2299, 'learning_rate': 2.391304347826087e-05, 'epoch': 5.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 371/690 [02:08<01:12,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2263, 'learning_rate': 2.318840579710145e-05, 'epoch': 5.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 381/690 [02:10<01:09,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1623, 'learning_rate': 2.246376811594203e-05, 'epoch': 5.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 391/690 [02:13<01:04,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1895, 'learning_rate': 2.173913043478261e-05, 'epoch': 5.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 401/690 [02:15<00:59,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3415, 'learning_rate': 2.101449275362319e-05, 'epoch': 5.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 411/690 [02:17<00:58,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3918, 'learning_rate': 2.028985507246377e-05, 'epoch': 5.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|██████    | 414/690 [02:18<00:54,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0860475301742554, 'eval_accuracy': 0.7463768115942029, 'eval_runtime': 0.748, 'eval_samples_per_second': 184.492, 'eval_steps_per_second': 24.064, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 61%|██████    | 421/690 [02:28<02:25,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2412, 'learning_rate': 1.956521739130435e-05, 'epoch': 6.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 431/690 [02:30<00:55,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0431, 'learning_rate': 1.8840579710144928e-05, 'epoch': 6.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 441/690 [02:32<00:51,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1092, 'learning_rate': 1.8115942028985507e-05, 'epoch': 6.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 451/690 [02:34<00:49,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1188, 'learning_rate': 1.739130434782609e-05, 'epoch': 6.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 461/690 [02:37<00:46,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3314, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 471/690 [02:39<00:45,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.14, 'learning_rate': 1.5942028985507246e-05, 'epoch': 6.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 481/690 [02:41<00:42,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1276, 'learning_rate': 1.5217391304347828e-05, 'epoch': 6.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 70%|███████   | 483/690 [02:42<00:40,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1864184141159058, 'eval_accuracy': 0.7681159420289855, 'eval_runtime': 0.744, 'eval_samples_per_second': 185.485, 'eval_steps_per_second': 24.194, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 71%|███████   | 491/690 [02:53<01:29,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0449, 'learning_rate': 1.4492753623188407e-05, 'epoch': 7.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 501/690 [02:55<00:40,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0593, 'learning_rate': 1.3768115942028985e-05, 'epoch': 7.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 511/690 [02:57<00:36,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0454, 'learning_rate': 1.3043478260869566e-05, 'epoch': 7.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 521/690 [02:59<00:34,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0304, 'learning_rate': 1.2318840579710146e-05, 'epoch': 7.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 531/690 [03:01<00:33,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1014, 'learning_rate': 1.1594202898550725e-05, 'epoch': 7.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 541/690 [03:03<00:31,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0805, 'learning_rate': 1.0869565217391305e-05, 'epoch': 7.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 551/690 [03:05<00:28,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0378, 'learning_rate': 1.0144927536231885e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|████████  | 552/690 [03:06<00:26,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5577775239944458, 'eval_accuracy': 0.782608695652174, 'eval_runtime': 0.7484, 'eval_samples_per_second': 184.395, 'eval_steps_per_second': 24.052, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 81%|████████▏ | 561/690 [03:17<00:48,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.019, 'learning_rate': 9.420289855072464e-06, 'epoch': 8.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 571/690 [03:19<00:25,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.011, 'learning_rate': 8.695652173913044e-06, 'epoch': 8.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 581/690 [03:21<00:22,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0031, 'learning_rate': 7.971014492753623e-06, 'epoch': 8.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 591/690 [03:23<00:20,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.021, 'learning_rate': 7.246376811594203e-06, 'epoch': 8.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 601/690 [03:25<00:18,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0182, 'learning_rate': 6.521739130434783e-06, 'epoch': 8.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 611/690 [03:27<00:16,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0366, 'learning_rate': 5.797101449275362e-06, 'epoch': 8.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 621/690 [03:29<00:13,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0018, 'learning_rate': 5.072463768115943e-06, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 90%|█████████ | 621/690 [03:30<00:13,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.750072956085205, 'eval_accuracy': 0.7753623188405797, 'eval_runtime': 0.7481, 'eval_samples_per_second': 184.464, 'eval_steps_per_second': 24.061, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 91%|█████████▏| 631/690 [03:41<00:19,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0002, 'learning_rate': 4.347826086956522e-06, 'epoch': 9.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 641/690 [03:43<00:10,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0007, 'learning_rate': 3.6231884057971017e-06, 'epoch': 9.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 651/690 [03:45<00:08,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 2.898550724637681e-06, 'epoch': 9.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 661/690 [03:48<00:05,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0025, 'learning_rate': 2.173913043478261e-06, 'epoch': 9.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 671/690 [03:50<00:03,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0088, 'learning_rate': 1.4492753623188406e-06, 'epoch': 9.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 681/690 [03:52<00:01,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 7.246376811594203e-07, 'epoch': 9.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [03:54<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 690/690 [03:54<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7938377857208252, 'eval_accuracy': 0.7753623188405797, 'eval_runtime': 0.6624, 'eval_samples_per_second': 208.319, 'eval_steps_per_second': 27.172, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [04:06<00:00,  2.80it/s]\n",
      "C:\\Users\\Ze\\AppData\\Local\\Temp\\ipykernel_23024\\3041598397.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 246.8062, 'train_samples_per_second': 22.204, 'train_steps_per_second': 2.796, 'train_loss': 0.40140211117045577, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 27.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5577775239944458,\n",
       " 'eval_accuracy': 0.782608695652174,\n",
       " 'eval_runtime': 0.693,\n",
       " 'eval_samples_per_second': 199.14,\n",
       " 'eval_steps_per_second': 25.975,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Ensure your model is on the correct device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set your batch size\n",
    "batch_size = 5  # Adjust this to a smaller number if your GPU memory is limited\n",
    "\n",
    "# Initialize an empty list to store logits from each batch\n",
    "all_logits = []\n",
    "\n",
    "# Process the data in batches\n",
    "for i in range(0, len(pred_encoding['input_ids']), batch_size):\n",
    "    # Extract the batch from pred_encoding\n",
    "    batch = {key: val[i:i + batch_size] for key, val in pred_encoding.items()}\n",
    "    \n",
    "    # Move batch to the same device as the model\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    # Forward pass without gradient calculation (to save memory)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        all_logits.append(logits)\n",
    "\n",
    "# Now, all_logits contains logits from each batch. You can concatenate them and process further.\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "# Apply softmax to convert logits to probabilities (if needed)\n",
    "probabilities = softmax(all_logits, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities tensor to CPU and then to a NumPy array\n",
    "probabilities_cpu = probabilities.cpu().numpy()\n",
    "\n",
    "# Now you can use the label_encoder to inverse transform the predictions\n",
    "mood_predictions = label_encoder.inverse_transform(probabilities_cpu.argmax(axis=1))\n",
    "\n",
    "# mood_predictions now contains the original mood labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "truck_data['predicted_mood'] = mood_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Calm\n",
       "1           Sad\n",
       "2          Calm\n",
       "3           Sad\n",
       "4           Sad\n",
       "          ...  \n",
       "170648    Happy\n",
       "170649    Happy\n",
       "170650    Happy\n",
       "170651    Happy\n",
       "170652    Happy\n",
       "Name: predicted_mood, Length: 170653, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_data['predicted_mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "truck_data.to_csv(\"data_music_with_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
