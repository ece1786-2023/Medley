{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain openai chromadb tiktoken\n",
        "\n",
        "import os\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "api_key = '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'\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "KK8ge14P7Is2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function that initializes the vector database\n",
        "def initialize_db(file_path, chunk_size=1000, chunk_overlap=0, persist_directory=\"./chroma_db\"):\n",
        "    # document loader\n",
        "    loader = CSVLoader(file_path=file_path)\n",
        "    data = loader.load()\n",
        "\n",
        "    # document transform\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs = text_splitter.split_documents(data)\n",
        "\n",
        "    # document embedding\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    # vector database\n",
        "    db = Chroma.from_documents(docs, embeddings, persist_directory=persist_directory)\n",
        "\n",
        "    return db"
      ],
      "metadata": {
        "id": "xq_s3O2Jmr3h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function that retrieves relevant documents based on the query from the database\n",
        "def retrieve(query, db, k=20):\n",
        "    # retriever\n",
        "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
        "\n",
        "    # retrieve documents\n",
        "    retrieved_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    return [doc.page_content for doc in retrieved_docs]"
      ],
      "metadata": {
        "id": "VkoX0AConf7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}