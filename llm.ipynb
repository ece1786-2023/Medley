{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjWKSkP7r6Ug"
      },
      "outputs": [],
      "source": [
        "%pip install openai ipynb\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from openai import OpenAI\n",
        "\n",
        "api_key = ''\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hadzam190kLQ"
      },
      "outputs": [],
      "source": [
        "# function that split the playlist into train and test set\n",
        "def split_train_test(playlist, test_size=0.1):\n",
        "\n",
        "    # random shuffle the playlist\n",
        "    tracks = playlist['tracks']\n",
        "    random.shuffle(tracks)\n",
        "\n",
        "    num_tracks = len(tracks)\n",
        "    num_test_tracks = int(num_tracks * test_size)\n",
        "\n",
        "    test_set = tracks[:num_test_tracks]\n",
        "    train_set = {\n",
        "        \"playlist_name\": playlist[\"playlist_name\"],\n",
        "        \"tracks\": tracks[num_test_tracks:]\n",
        "    }\n",
        "\n",
        "    return train_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fieZ8zhRCCD2"
      },
      "outputs": [],
      "source": [
        "# function that convert playlist dictionary to string\n",
        "def to_str(playlist):\n",
        "    playlist_str = f\"Playlist Name: {playlist['playlist_name']}\\n\"\n",
        "    playlist_str += \"Tracks:\\n\"\n",
        "    for track in playlist['tracks']:\n",
        "        playlist_str += f\"- {track['track_name']} by {track['artist_name']}\\n\"\n",
        "\n",
        "    return playlist_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hdL5Qya4v3Gr"
      },
      "outputs": [],
      "source": [
        "# function that prompt the llm to generate response\n",
        "def generate(system_prompt, user_input):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ],\n",
        "            temperature=0, # using greedy decoding\n",
        "            max_tokens=256,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "          )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aAJjmkNctY5J"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "input_file = 'cleaned_playlists.json'\n",
        "with open(input_file, 'r') as inputFile:\n",
        "    data = json.load(inputFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QMjWUFfawMF6"
      },
      "outputs": [],
      "source": [
        "# prompts\n",
        "feature_prompt = ''\n",
        "recommendation_prompt = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCV5qNsA7UGo"
      },
      "outputs": [],
      "source": [
        "# main loop\n",
        "for playlist in data['playlists']:\n",
        "    train_set, test_set = split_train_test(playlist)\n",
        "    train_set_str = to_str(train_set)\n",
        "    features = generate(feature_prompt, train_set_str)\n",
        "    user_input = train_set_str + \"\\n\" + features\n",
        "    recommendations = generate(recommendation_prompt, user_input)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
